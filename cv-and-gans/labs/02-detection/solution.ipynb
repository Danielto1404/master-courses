{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# !pip install mat73\n",
    "\n",
    "import os\n",
    "\n",
    "import mat73\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.utils.data as td\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ],
   "metadata": {
    "id": "Fte-n2JDl2v6",
    "execution": {
     "iopub.status.busy": "2022-10-26T13:46:16.954041Z",
     "iopub.execute_input": "2022-10-26T13:46:16.955069Z",
     "iopub.status.idle": "2022-10-26T13:46:16.961730Z",
     "shell.execute_reply.started": "2022-10-26T13:46:16.955031Z",
     "shell.execute_reply": "2022-10-26T13:46:16.960697Z"
    },
    "trusted": true
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def draw_boxes(img, boxes, linewidth=1):\n",
    "    img = img.numpy().transpose(1, 2, 0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "    ax.imshow(img)\n",
    "\n",
    "    colors = [\"orange\", \"green\", \"pink\"]\n",
    "\n",
    "    for i, bbox in enumerate(boxes):\n",
    "        bbox = bbox.detach().cpu()\n",
    "\n",
    "        x0, y0, x1, y1 = bbox[0].item(), bbox[1].item(), bbox[2].item(), bbox[3].item()\n",
    "        x, y, w, h = x0, y0, x1 - x0, y1 - y0\n",
    "\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=linewidth, edgecolor=colors[i % len(colors)], facecolor=\"none\")\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T13:46:16.965189Z",
     "iopub.execute_input": "2022-10-26T13:46:16.965536Z",
     "iopub.status.idle": "2022-10-26T13:46:16.976400Z",
     "shell.execute_reply.started": "2022-10-26T13:46:16.965505Z",
     "shell.execute_reply": "2022-10-26T13:46:16.975443Z"
    },
    "trusted": true
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def parse_annotation(ann):\n",
    "    one_box = not isinstance(ann[\"label\"], list)\n",
    "\n",
    "    if one_box:\n",
    "        x, y, w, h = ann[\"left\"].item(), ann[\"top\"].item(), ann[\"width\"].item(), ann[\"height\"].item()\n",
    "        bboxes = [x, y, x + w, y + h]\n",
    "        labels = [ann[\"label\"].item()]\n",
    "    else:\n",
    "        bboxes = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(ann[\"label\"])):\n",
    "            x, y, w, h = ann[\"left\"][i].item(), ann[\"top\"][i].item(), ann[\"width\"][i].item(), ann[\"height\"][i].item()\n",
    "            bboxes.append([x, y, x + w, y + h])\n",
    "            labels.append(ann[\"label\"][i].item())\n",
    "\n",
    "    labels = torch.tensor(labels).long()\n",
    "    bboxes = torch.tensor(bboxes).float()\n",
    "\n",
    "    return bboxes, labels"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T14:03:15.271292Z",
     "iopub.execute_input": "2022-10-26T14:03:15.271989Z",
     "iopub.status.idle": "2022-10-26T14:03:15.282375Z",
     "shell.execute_reply.started": "2022-10-26T14:03:15.271953Z",
     "shell.execute_reply": "2022-10-26T14:03:15.281369Z"
    },
    "trusted": true
   },
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "IMAGE_SIZE = (256, 512)\n",
    "\n",
    "IMAGE_TRANSFORM = transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(IMAGE_SIZE)\n",
    "])\n",
    "\n",
    "\n",
    "class DetectionDataset(td.Dataset):\n",
    "    def __init__(self, folder, labels):\n",
    "        self.folder = folder\n",
    "        self.names = labels[\"name\"]\n",
    "        self.bboxes = labels[\"bbox\"]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        name = self.names[index]\n",
    "        image = Image.open(f\"{self.folder}/{name}\")\n",
    "        w, h = image.width, image.height\n",
    "        image = IMAGE_TRANSFORM(image)\n",
    "\n",
    "        bboxes, labels = parse_annotation(self.bboxes[index])\n",
    "\n",
    "        nh, nw = IMAGE_SIZE\n",
    "        scale_ = torch.tensor([nw / w, nh / h, nw / w, nh / h])\n",
    "        bboxes = bboxes * scale_\n",
    "\n",
    "        return image, bboxes, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)"
   ],
   "metadata": {
    "id": "rT43SYIWl2v7",
    "execution": {
     "iopub.status.busy": "2022-10-26T14:03:19.385422Z",
     "iopub.execute_input": "2022-10-26T14:03:19.385801Z",
     "iopub.status.idle": "2022-10-26T14:03:19.396562Z",
     "shell.execute_reply.started": "2022-10-26T14:03:19.385769Z",
     "shell.execute_reply": "2022-10-26T14:03:19.395262Z"
    },
    "trusted": true
   },
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: DetectionDataset,\n",
    "            batch_size: int = 32\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.batch_sz = batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        images, bboxes, labels = [], [], []\n",
    "\n",
    "        for image, bbox, label in batch:\n",
    "            images.append(image)\n",
    "            bboxes.append(bbox)\n",
    "            labels.append(label)\n",
    "\n",
    "        return torch.stack(images, dim=0), bboxes, labels\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return td.DataLoader(self.dataset, batch_size=self.batch_sz, shuffle=True, collate_fn=self.collate_fn)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T14:03:19.781504Z",
     "iopub.execute_input": "2022-10-26T14:03:19.781888Z",
     "iopub.status.idle": "2022-10-26T14:03:19.789867Z",
     "shell.execute_reply.started": "2022-10-26T14:03:19.781855Z",
     "shell.execute_reply": "2022-10-26T14:03:19.788904Z"
    },
    "trusted": true
   },
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Detector(pl.LightningModule):\n",
    "    def __init__(self, torch_model):\n",
    "        super().__init__()\n",
    "        self.model = torch_model\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        images, bboxes, labels = batch\n",
    "\n",
    "        targets = [\n",
    "            {\"boxes\": boxes, \"labels\": label} for boxes, label in zip(bboxes, labels)\n",
    "        ]\n",
    "\n",
    "        out = self.model(images, targets)\n",
    "        loss = 5 * out[\"loss_box_reg\"] + 2.5 * out[\"loss_rpn_box_reg\"] + 0.1 * out[\"loss_objectness\"] + out[\n",
    "            \"loss_classifier\"]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.NAdam(self.model.parameters(), lr=1e-4)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T14:09:01.571388Z",
     "iopub.execute_input": "2022-10-26T14:09:01.571764Z",
     "iopub.status.idle": "2022-10-26T14:09:01.579448Z",
     "shell.execute_reply.started": "2022-10-26T14:09:01.571732Z",
     "shell.execute_reply": "2022-10-26T14:09:01.578442Z"
    },
    "trusted": true
   },
   "execution_count": 92,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize data module"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "train_labels = mat73.loadmat(\"../input/street-view-house-numbers/train_digitStruct.mat\")\n",
    "\n",
    "train = DetectionDataset(\n",
    "    folder=\"../input/street-view-house-numbers/train/train\",\n",
    "    labels=train_labels[\"digitStruct\"]\n",
    ")\n",
    "\n",
    "train_data_module = DataModule(train, batch_size=32)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T14:09:02.012064Z",
     "iopub.execute_input": "2022-10-26T14:09:02.012807Z",
     "iopub.status.idle": "2022-10-26T14:09:02.021046Z",
     "shell.execute_reply.started": "2022-10-26T14:09:02.012768Z",
     "shell.execute_reply": "2022-10-26T14:09:02.019787Z"
    },
    "trusted": true
   },
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "text": "CPU times: user 52 µs, sys: 2 µs, total: 54 µs\nWall time: 62 µs\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define detection model and trainer. In my case it's *Faster-RCNN*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "NUM_CLASSES = 11\n",
    "\n",
    "fasterrcnn = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "fasterrcnn.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "    fasterrcnn.roi_heads.box_predictor.cls_score.in_features,\n",
    "    NUM_CLASSES\n",
    ")\n",
    "\n",
    "fasterrcnn.transform = GeneralizedRCNNTransform(\n",
    "    min_size=min(IMAGE_SIZE),\n",
    "    max_size=max(IMAGE_SIZE),\n",
    "    image_mean=[0.485, 0.456, 0.406],\n",
    "    image_std=[0.229, 0.224, 0.225]\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T14:09:02.375583Z",
     "iopub.execute_input": "2022-10-26T14:09:02.375965Z",
     "iopub.status.idle": "2022-10-26T14:09:03.080453Z",
     "shell.execute_reply.started": "2022-10-26T14:09:02.375933Z",
     "shell.execute_reply": "2022-10-26T14:09:03.079425Z"
    },
    "trusted": true
   },
   "execution_count": 94,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Configure lightning _trainer_ and _detector_"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "detector = Detector(fasterrcnn)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, max_epochs=1)\n",
    "\n",
    "trainer.fit(detector, train_data_module)"
   ],
   "metadata": {
    "id": "NXyrsQ1jl2v9",
    "execution": {
     "iopub.status.busy": "2022-10-26T14:09:03.273333Z",
     "iopub.execute_input": "2022-10-26T14:09:03.273707Z",
     "iopub.status.idle": "2022-10-26T14:35:26.018415Z",
     "shell.execute_reply.started": "2022-10-26T14:09:03.273675Z",
     "shell.execute_reply": "2022-10-26T14:35:26.017392Z"
    },
    "trusted": true
   },
   "execution_count": 95,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1435f1bce7a4ca082532fc885ac7600"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(fasterrcnn, \"fasterrcnn.pth\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T14:35:26.020442Z",
     "iopub.execute_input": "2022-10-26T14:35:26.020794Z",
     "iopub.status.idle": "2022-10-26T14:35:26.403678Z",
     "shell.execute_reply.started": "2022-10-26T14:35:26.020758Z",
     "shell.execute_reply": "2022-10-26T14:35:26.402403Z"
    },
    "trusted": true
   },
   "execution_count": 96,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torchvision.ops import nms\n",
    "\n",
    "\n",
    "def evaluate(path, model, filter_threshold=0.5, iou_threshold=0.5, device=\"cpu\"):\n",
    "    img = Image.open(path)\n",
    "    w, h = img.width, img.height\n",
    "    x = IMAGE_TRANSFORM(img).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(x)[0]\n",
    "\n",
    "    hi, wi = IMAGE_SIZE\n",
    "    scale = torch.tensor([w / wi, h / hi, w / wi, h / hi])\n",
    "\n",
    "    bboxes = output[\"boxes\"].cpu() * scale\n",
    "    scores = output[\"scores\"].cpu()\n",
    "    sliced = scores > filter_threshold\n",
    "    indices = nms(bboxes[sliced], scores[sliced], iou_threshold=iou_threshold)\n",
    "\n",
    "    draw_boxes(transforms.ToTensor()(img), bboxes[indices])\n",
    "\n",
    "    return dict(bboxes=bboxes[indices], scores=scores[indices])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T14:36:28.092198Z",
     "iopub.execute_input": "2022-10-26T14:36:28.092591Z",
     "iopub.status.idle": "2022-10-26T14:36:28.101166Z",
     "shell.execute_reply.started": "2022-10-26T14:36:28.092561Z",
     "shell.execute_reply": "2022-10-26T14:36:28.099951Z"
    },
    "trusted": true
   },
   "execution_count": 103,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_folder = \"../input/street-view-house-numbers/test/test\"\n",
    "test_images = os.listdir(test_folder)\n",
    "\n",
    "index = 3\n",
    "path = f\"{test_folder}/{test_images[index]}\"\n",
    "\n",
    "evaluate(path, fasterrcnn, filter_threshold=0.5, iou_threshold=0.9, device=\"cuda\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T14:45:32.227578Z",
     "iopub.execute_input": "2022-10-26T14:45:32.228292Z",
     "iopub.status.idle": "2022-10-26T14:45:32.482925Z",
     "shell.execute_reply.started": "2022-10-26T14:45:32.228245Z",
     "shell.execute_reply": "2022-10-26T14:45:32.482034Z"
    },
    "trusted": true
   },
   "execution_count": 109,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 864x648 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "execution_count": 109,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'bboxes': tensor([[19.7326,  3.7733, 29.1934, 19.3896],\n         [38.0371,  4.7012, 47.2237, 19.2056],\n         [28.8806,  4.8031, 37.8466, 18.8457],\n         [29.5291,  3.4606, 38.4221, 18.5813],\n         [20.4155,  4.7405, 29.4878, 18.4652],\n         [29.8247,  4.6674, 37.7063, 19.4005],\n         [37.7934,  3.9098, 47.7024, 20.3458],\n         [29.5234,  4.7776, 38.2033, 18.6219],\n         [19.8731,  4.5639, 29.3203, 18.3601],\n         [23.3060,  4.6965, 33.1244, 19.5553]]),\n 'scores': tensor([0.9537, 0.9359, 0.9083, 0.1769, 0.1114, 0.1085, 0.0939, 0.0679, 0.0663,\n         0.0511])}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "\n",
    "def mAP(loader, model, thresholds: List[float], device=\"cpu\"):\n",
    "    metric = MeanAveragePrecision(iou_thresholds=thresholds)\n",
    "\n",
    "    model.eval().to(device)\n",
    "\n",
    "    for images, bboxes, labels in tqdm(loader):\n",
    "        targets = [\n",
    "            {\"boxes\": boxes.to(device), \"labels\": label.to(device)} for boxes, label in zip(bboxes, labels)\n",
    "        ]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images.to(device))\n",
    "\n",
    "        metric.update(outputs, targets)\n",
    "\n",
    "    return metric.compute()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T14:45:41.484935Z",
     "iopub.execute_input": "2022-10-26T14:45:41.485624Z",
     "iopub.status.idle": "2022-10-26T14:45:41.492760Z",
     "shell.execute_reply.started": "2022-10-26T14:45:41.485587Z",
     "shell.execute_reply": "2022-10-26T14:45:41.491697Z"
    },
    "trusted": true
   },
   "execution_count": 110,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "test_labels = mat73.loadmat(\"../input/street-view-house-numbers/test_digitStruct.mat\")\n",
    "\n",
    "test = DetectionDataset(\n",
    "    folder=\"../input/street-view-house-numbers/test/test\",\n",
    "    labels=test_labels[\"digitStruct\"]\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T14:45:44.924248Z",
     "iopub.execute_input": "2022-10-26T14:45:44.924614Z",
     "iopub.status.idle": "2022-10-26T14:47:40.174969Z",
     "shell.execute_reply.started": "2022-10-26T14:45:44.924584Z",
     "shell.execute_reply": "2022-10-26T14:47:40.173899Z"
    },
    "trusted": true
   },
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "text": "CPU times: user 1min 53s, sys: 1.49 s, total: 1min 54s\nWall time: 1min 55s\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_loader = td.DataLoader(test, batch_size=64, collate_fn=train_data_module.collate_fn)\n",
    "\n",
    "mean_ap = mAP(test_loader, fasterrcnn.eval(), device=\"cuda\", thresholds=[0.5, 0.75, 0.9])\n",
    "mean_ap"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-26T14:50:44.980650Z",
     "iopub.execute_input": "2022-10-26T14:50:44.981028Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'map': tensor(0.3479),\n 'map_50': tensor(0.8082),\n 'map_75': tensor(0.2326),\n 'map_small': tensor(0.1181),\n 'map_medium': tensor(0.2930),\n 'map_large': tensor(0.3832),\n 'mar_1': tensor(0.4277),\n 'mar_10': tensor(0.4663),\n 'mar_100': tensor(0.4664),\n 'mar_small': tensor(0.2047),\n 'mar_medium': tensor(0.4595),\n 'mar_large': tensor(0.5147),\n 'map_per_class': tensor(-1.),\n 'mar_100_per_class': tensor(-1.)}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def iou_precision_recall(t: box, p: box):\n",
    "    t = box(*t)\n",
    "    p = box(*p)\n",
    "\n",
    "    inner = p.intersection(t).area\n",
    "    iou = inner / p.union(t).area\n",
    "    precision = inner / p.area\n",
    "    recall = inner / t.area\n",
    "\n",
    "    return iou, precision, recall\n",
    "\n",
    "\n",
    "def precision_recall(loader, model, device=\"cuda\"):\n",
    "    model.eval()\n",
    "\n",
    "    ious = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for images, bboxes, _ in tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images.to(device))\n",
    "\n",
    "        for predicted, target in zip(outputs, bboxes):\n",
    "            target_metrics = []\n",
    "            for t in target:\n",
    "                iou, precision, recall = 0, 0, 0\n",
    "                for p in predicted[\"boxes\"]:\n",
    "                    p = p.cpu()\n",
    "                    _iou, _precision, _recall = iou_precision_recall(t, p)\n",
    "                    if _iou > iou:\n",
    "                        iou = _iou\n",
    "                        precision = _precision\n",
    "                        recall = _recall\n",
    "\n",
    "                target_metrics.append([iou, precision, recall])\n",
    "\n",
    "            ious.append(np.array(target_metrics)[:, 0].mean())\n",
    "            precisions.append(np.array(target_metrics)[:, 1].mean())\n",
    "            recalls.append(np.array(target_metrics)[:, 2].mean())\n",
    "\n",
    "    iou = np.array(ious).mean()\n",
    "    precision = np.array(precisions).mean()\n",
    "    recall = np.array(recalls).mean()\n",
    "\n",
    "    return iou, precision, recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iou, precision, recall = precision_recall(test_loader, fasterrcnn, device=\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU: 0.7361\n",
      "Precision: 0.8334\n",
      "Recall: 0.8763\n"
     ]
    }
   ],
   "source": [
    "print(f\"IoU: {iou:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
