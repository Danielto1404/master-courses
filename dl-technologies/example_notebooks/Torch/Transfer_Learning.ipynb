{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEcajD4h0zga",
        "outputId": "96c8bc47-6370-424d-bd71-d629157d0252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIaNPfqN1Nn6",
        "outputId": "22509ead-e63b-4267-e956-065fdf119e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.12.1+cu113)\n",
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.5.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.25.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.1->torchdata) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "! pip install torchdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hATn5_kt0e4k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import transformers\n",
        "import collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37UHL-wM1mYU"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "vocab = None\n",
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLFAifDT1Epz"
      },
      "outputs": [],
      "source": [
        "def load_dataset(ngrams=1,min_freq=1):\n",
        "    print(\"Loading dataset...\")\n",
        "    train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='./data')\n",
        "    train_dataset = list(train_dataset)\n",
        "    test_dataset = list(test_dataset)\n",
        "    classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
        "    print('Building vocab...')\n",
        "    counter = collections.Counter()\n",
        "    for (label, line) in train_dataset:\n",
        "        counter.update(torchtext.data.utils.ngrams_iterator(tokenizer(line),ngrams=ngrams))\n",
        "    vocab = torchtext.vocab.vocab(counter, min_freq=min_freq)\n",
        "    return train_dataset,test_dataset,classes,vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWzI9BMw0g7h",
        "outputId": "3834e55c-bd74-4e2e-ebea-2eece96aa976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Building vocab...\n"
          ]
        }
      ],
      "source": [
        "train_dataset, test_dataset, classes, vocab = load_dataset()\n",
        "vocab_len = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxfvBD241F7U"
      },
      "outputs": [],
      "source": [
        "# To load the model from Internet repository using model name. \n",
        "# Use this if you are running from your own copy of the notebooks\n",
        "bert_model = 'bert-base-uncased' \n",
        "\n",
        "\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(bert_model)\n",
        "\n",
        "MAX_SEQ_LEN = 128\n",
        "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
        "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"I love Python\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uap-zr4_aaIB",
        "outputId": "4e085db5-0f72-4ced-df5c-34f068bac9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 1045, 2293, 18750, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVmfObYo3llB"
      },
      "outputs": [],
      "source": [
        "def pad_bert(b):\n",
        "    # b is the list of tuples of length batch_size\n",
        "    #   - first element of a tuple = label, \n",
        "    #   - second = feature (text sequence)\n",
        "    # build vectorized sequence\n",
        "    v = [tokenizer.encode(x[1]) for x in b]\n",
        "    # compute max length of a sequence in this minibatch\n",
        "    l = max(map(len,v))\n",
        "    return ( # tuple of two tensors - labels and features\n",
        "        torch.LongTensor([t[0] for t in b]),\n",
        "        torch.stack([torch.nn.functional.pad(torch.tensor(t),(0,l-len(t)),mode='constant',value=0) for t in v])\n",
        "    )\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, collate_fn=pad_bert, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, collate_fn=pad_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ32QEJ23pdu",
        "outputId": "637e4a22-c6f9-4a75-d611-5d542cec8e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = transformers.BertForSequenceClassification.from_pretrained(bert_model,num_labels=4).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqXlMg5e3uOL",
        "outputId": "4dac49a9-aeb3-4f7d-9bf1-8a3c4eb61dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 1.2824830627441406, Accuracy = 0.45\n",
            "Loss = 0.6098806762695312, Accuracy = 0.8325\n",
            "Loss = 0.44724437713623044, Accuracy = 0.8375\n",
            "Loss = 0.33023513793945314, Accuracy = 0.895\n",
            "Loss = 0.30666357040405273, Accuracy = 0.9\n",
            "Loss = 0.3575618743896484, Accuracy = 0.88\n",
            "Loss = 0.3329682159423828, Accuracy = 0.89\n",
            "Loss = 0.2890250778198242, Accuracy = 0.885\n",
            "Loss = 0.32768016815185547, Accuracy = 0.8975\n",
            "Loss = 0.281107177734375, Accuracy = 0.915\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "report_freq = 50\n",
        "iterations = 500 # make this larger to train for longer time!\n",
        "\n",
        "model.train()\n",
        "\n",
        "i,c = 0,0\n",
        "acc_loss = 0\n",
        "acc_acc = 0\n",
        "\n",
        "for labels,texts in train_loader:\n",
        "    labels = labels.to(device)-1 # get labels in the range 0-3         \n",
        "    texts = texts.to(device)\n",
        "    loss, out = model(texts, labels=labels)[:2]\n",
        "    labs = out.argmax(dim=1)\n",
        "    acc = torch.mean((labs==labels).type(torch.float32))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    acc_loss += loss\n",
        "    acc_acc += acc\n",
        "    i+=1\n",
        "    c+=1\n",
        "    if i%report_freq==0:\n",
        "        print(f\"Loss = {acc_loss.item()/c}, Accuracy = {acc_acc.item()/c}\")\n",
        "        c = 0\n",
        "        acc_loss = 0\n",
        "        acc_acc = 0\n",
        "    iterations-=1\n",
        "    if not iterations:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtSh83l23yO8",
        "outputId": "0d3851c4-c2dc-4cc8-95db-f0762e35ece3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy: 0.8948019801980198\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "iterations = 100\n",
        "acc = 0\n",
        "i = 0\n",
        "for labels,texts in test_loader:\n",
        "    labels = labels.to(device)-1      \n",
        "    texts = texts.to(device)\n",
        "    _, out = model(texts, labels=labels)[:2]\n",
        "    labs = out.argmax(dim=1)\n",
        "    acc += torch.mean((labs==labels).type(torch.float32))\n",
        "    i+=1\n",
        "    if i>iterations: break\n",
        "        \n",
        "print(f\"Final accuracy: {acc.item()/i}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LOBZt-anbbKv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}