{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sztkFWHKkqm",
        "outputId": "7afe8728-f4db-4dab-f113-59f8010376f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.executing_eagerly()) # режим активного выполнения"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykg6nz0eoHFU",
        "outputId": "4f45a7b1-0e68-4489-876e-53ad9cd2d55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1,2],[3,4]])\n",
        "print(a)\n",
        "b = tf.constant([1, 2, 3, 4])\n",
        "print(b)\n",
        "c = tf.constant([[1,2],\n",
        "                 [3,4],\n",
        "                 [5,6]], dtype=tf.float16)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f8eYWm5pV0q",
        "outputId": "0023ee2a-91bb-4ca7-c3ed-ae85f419788b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]], shape=(3, 2), dtype=float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = tf.constant([[1,2],\n",
        "                 [3,4 ,5],\n",
        "                 [5,6]], dtype=tf.float16)\n",
        "print(c) # Только прямоугольные матрицы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "ovH1HEwkp9uP",
        "outputId": "0ef0adc7-8966-47ca-c10f-77844123ac63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-17e4742e5a3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m c = tf.constant([[1,2],\n\u001b[1;32m      2\u001b[0m                  \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  [5,6]], dtype=tf.float16)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Только прямоугольные матрицы\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m    267\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 268\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "с2 = tf.cast(c, dtype=tf.float32)\n",
        "print(с2)"
      ],
      "metadata": {
        "id": "a_By0zUVqIgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232de363-c163-495e-9039-cab5180abff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v1 = tf.Variable(-1)\n",
        "v2 = tf.Variable(b)\n",
        "print(v1)\n",
        "print(v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCoZqBx4qSrk",
        "outputId": "c42f5727-bdbd-4325-8268-de6b850ac8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=-1>\n",
            "<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v1.assign(0)\n",
        "print(v1)\n",
        "v2.assign([0, 1, 7, 8])\n",
        "print(v2)\n",
        "v2.assign([0, 1, 7]) # Raise Exception"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "H-1BYlQxq4M3",
        "outputId": "598293be-9d33-40df-efcc-003862026823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0>\n",
            "<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([0, 1, 7, 8], dtype=int32)>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-b58128d3d21b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Raise Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    939\u001b[0m           \u001b[0mtensor_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         raise ValueError(\n\u001b[0;32m--> 941\u001b[0;31m             (f\"Cannot assign value to variable '{tensor_name}': Shape mismatch.\"\n\u001b[0m\u001b[1;32m    942\u001b[0m              \u001b[0;34mf\"The variable shape {self._shape}, and the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m              f\"assigned value shape {value_tensor.shape} are incompatible.\"))\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot assign value to variable ' Variable:0': Shape mismatch.The variable shape (4,), and the assigned value shape (3,) are incompatible."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v2.assign_add([1, 1, 1, 1]) # Добавление значений\n",
        "v1.assign_sub(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWTRbh-7sTGH",
        "outputId": "816e59ef-715c-43bd-d96f-bbf0e69b7dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=int32, numpy=-10>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_0 = v2[0]\n",
        "print(val_0)\n",
        "val_12 = v2[1:3]\n",
        "print(val_12)\n",
        "val_0.assign(10)\n",
        "print(val_0)\n",
        "print(v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XpzzrclvcIh",
        "outputId": "b92c505c-5b7d-42a9-d816-2c7c56c5d1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor([3 9], shape=(2,), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([10,  3,  9, 10], dtype=int32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1,2],[3,4]])\n",
        "print(a)\n",
        "a = tf.random.normal(shape=(10,3), dtype=tf.float64)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z2O37gboLaA",
        "outputId": "ef798d5b-ed0e-4274-bca5-2111f0af74d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 1.42990034 -0.85242201 -0.17607377]\n",
            " [-0.43083898 -0.56763698  0.10498785]\n",
            " [ 1.0055119  -0.51386224  1.65042604]\n",
            " [-0.07642433  0.94617314 -0.85343946]\n",
            " [-0.36974769 -1.09051717 -0.2154226 ]\n",
            " [-1.57370513  1.74964359  1.74689659]\n",
            " [ 1.23304884  0.25744586 -2.0021853 ]\n",
            " [-0.74895998  0.25355869 -1.78984496]\n",
            " [ 0.72332367  0.7801889   1.18340416]\n",
            " [ 1.39451151 -0.30267391 -1.73879514]], shape=(10, 3), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x =tf.constant(range(10)) + 5\n",
        "x_indx = tf.gather(x, [0, 4])\n",
        "print(x, x_indx, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpCPHhEFDfhu",
        "outputId": "877c163b-4dba-435e-90fb-1a5fb6937641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 5  6  7  8  9 10 11 12 13 14], shape=(10,), dtype=int32)\n",
            "tf.Tensor([5 9], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v2 = tf.constant([[1,2,7], [3,4,5], [5,6,7]])\n",
        "val_indx = v2[1,2]\n",
        "print(val_indx)\n",
        "print(v2[1:, 1]) # start:stop:step"
      ],
      "metadata": {
        "id": "ppFNclCKDro8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant(range(30))\n",
        "b = tf.reshape(a, [5,6])\n",
        "print(b.numpy())\n",
        "print(tf.reshape(a, [-1, 6]).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30pyEwiKERUj",
        "outputId": "cf520038-b147-4b27-ccab-e4360114cc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]\n",
            " [24 25 26 27 28 29]]\n",
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]\n",
            " [24 25 26 27 28 29]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.zeros((3,3)))\n",
        "print(tf.zeros_like(b))\n",
        "print(tf.eye(3, 3))\n",
        "print(tf.fill((3,3), 3))\n",
        "print(tf.ones((3,3)))\n",
        "print(tf.ones_like(b))\n",
        "print(tf.identity(b))"
      ],
      "metadata": {
        "id": "qqEOou9GE5fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(-1.0)\n",
        "y = lambda : x ** 2  - x\n",
        "N = 100\n",
        "opt = tf.optimizers.SGD(learning_rate=0.1)\n",
        "for n in range(N):\n",
        "  opt.minimize(y, [x])\n",
        "\n",
        "print(x.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZjIUAf5npI0",
        "outputId": "58685f6c-a704-46f7-8591-2cae70ef8c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.49999994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.random.normal((2,4), 0 , 0.1))\n",
        "print(tf.random.uniform((2,2), -1, 1))\n",
        "print(tf.random.truncated_normal((1,5), 0, 1))"
      ],
      "metadata": {
        "id": "dhB1eKi_FzBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([1, 2, 3])\n",
        "b = tf.constant([9, 8 , 7])\n",
        "print(tf.add(a, b))\n",
        "print(a + b)\n",
        "print(tf.subtract(a, b))\n",
        "print(a - b)\n",
        "print(tf.divide(a, b))\n",
        "print( a / b)\n",
        "print(tf.multiply(a, b))\n",
        "print(a * b)\n",
        "print(a // b)\n",
        "print(a ** 2)\n",
        "print(tf.tensordot(a, b, axes=0))\n",
        "print(tf.tensordot(b, a, axes=0))\n",
        "\n",
        "print(tf.tensordot(a, b, axes=1))\n",
        "print(tf.matmul(tf.tensordot(a, b, axes=0), tf.tensordot(b, a, axes=0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XpWiFKcGZ0S",
        "outputId": "be679aeb-d842-4b5c-f259-7c3682804b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10 10 10], shape=(3,), dtype=int32)\n",
            "tf.Tensor([10 10 10], shape=(3,), dtype=int32)\n",
            "tf.Tensor([-8 -6 -4], shape=(3,), dtype=int32)\n",
            "tf.Tensor([-8 -6 -4], shape=(3,), dtype=int32)\n",
            "tf.Tensor([0.11111111 0.25       0.42857143], shape=(3,), dtype=float64)\n",
            "tf.Tensor([0.11111111 0.25       0.42857143], shape=(3,), dtype=float64)\n",
            "tf.Tensor([ 9 16 21], shape=(3,), dtype=int32)\n",
            "tf.Tensor([ 9 16 21], shape=(3,), dtype=int32)\n",
            "tf.Tensor([0 0 0], shape=(3,), dtype=int32)\n",
            "tf.Tensor([1 4 9], shape=(3,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 9  8  7]\n",
            " [18 16 14]\n",
            " [27 24 21]], shape=(3, 3), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 9 18 27]\n",
            " [ 8 16 24]\n",
            " [ 7 14 21]], shape=(3, 3), dtype=int32)\n",
            "tf.Tensor(46, shape=(), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 194  388  582]\n",
            " [ 388  776 1164]\n",
            " [ 582 1164 1746]], shape=(3, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsGeM_N2Ln1j",
        "outputId": "d3e0faef-903b-46e8-cb0e-1cd1d0a6ece4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=24>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "tf.reduce_sum(b,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.sin(tf.Variable(3.14))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiDifByvHgI2",
        "outputId": "5b6a2763-d407-47a8-836b-234a65e8a96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.001592548>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vRqaQY7Lr4M",
        "outputId": "ea1796ce-dc90-4358-bbfe-b9ceb3a60c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-0.5887585  -0.86679506]\n",
            " [ 0.1370973  -0.6154888 ]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "a = tf.random.normal(shape=(2, 2))\n",
        "b = tf.random.normal(shape=(2, 2))\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(a)  # Start recording the history of operations applied to `a`\n",
        "  tape.watch(b)\n",
        "  c = tf.sqrt(tf.square(a) + tf.square(b))  # Do some math using `a`\n",
        "  # What's the gradient of `c` with respect to `a`?\n",
        "  dc_db = tape.gradient(c, b)\n",
        "  print(dc_db)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S3za8NPy5T5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "urT6WVsT5WHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wvLU9GNl5WD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jeF-m32p5WA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HYbuU_fU5V9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ep9hC2ti5V6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D3myzkVx5Vzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7D_7SVvS5VwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r_WhwiKv5Vp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTKXIfS65VjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ApIBlpVx5Vb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sQkdfJok5VTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UyAMkGTd5VLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "WDI60dc_TRVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUNn3JEXLyWq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification, make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMwZCER-L0kc"
      },
      "outputs": [],
      "source": [
        "np.random.seed(13) # pick the seed for reproducability - change it to explore the effects of random variations\n",
        "\n",
        "train_x = np.linspace(0, 3, 120)\n",
        "train_labels = 2 * train_x + 0.9 + np.random.randn(*train_x.shape) * 0.5 # 2x + 0.9 + Noise\n",
        "\n",
        "plt.scatter(train_x,train_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoyTbCZXL2I7"
      },
      "outputs": [],
      "source": [
        "input_dim = 1\n",
        "output_dim = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "# This is our weight matrix\n",
        "w = tf.Variable([[100.0]])\n",
        "# This is our bias vector\n",
        "b = tf.Variable(tf.zeros(shape=(output_dim,)))\n",
        "\n",
        "def f(x):\n",
        "  return tf.matmul(x,w) + b\n",
        "\n",
        "def compute_loss(labels, predictions):\n",
        "  return tf.reduce_mean(tf.square(labels - predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQsXZeejMA-z"
      },
      "outputs": [],
      "source": [
        "def train_on_batch(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = f(x)\n",
        "    loss = compute_loss(y, predictions)\n",
        "    # Note that `tape.gradient` works with a list as well (w, b).\n",
        "    dloss_dw, dloss_db = tape.gradient(loss, [w, b])\n",
        "  w.assign_sub(learning_rate * dloss_dw)\n",
        "  b.assign_sub(learning_rate * dloss_db)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow7HpTGqME9m"
      },
      "outputs": [],
      "source": [
        "# Shuffle the data.\n",
        "indices = np.random.permutation(len(train_x))\n",
        "features = tf.constant(train_x[indices],dtype=tf.float32)\n",
        "labels = tf.constant(train_labels[indices],dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu3u9PH3MGeU"
      },
      "outputs": [],
      "source": [
        "%time\n",
        "batch_size = 4\n",
        "for epoch in range(10):\n",
        "  for i in range(0,len(features),batch_size):\n",
        "    loss = train_on_batch(tf.reshape(features[i:i+batch_size],(-1,1)),tf.reshape(labels[i:i+batch_size],(-1,1)))\n",
        "  print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZmsfOvYMH0m"
      },
      "outputs": [],
      "source": [
        "w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kqj1igkUMLvk"
      },
      "outputs": [],
      "source": [
        "plt.scatter(train_x,train_labels)\n",
        "x = np.array([min(train_x),max(train_x)])\n",
        "y = w.numpy()[0,0]*x+b.numpy()[0]\n",
        "plt.plot(x,y,color='red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6XUX1OxMOf_"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_on_batch(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = f(x)\n",
        "    loss = compute_loss(y, predictions)\n",
        "    # Note that `tape.gradient` works with a list as well (w, b).\n",
        "    dloss_dw, dloss_db = tape.gradient(loss, [w, b])\n",
        "  w.assign_sub(learning_rate * dloss_dw)\n",
        "  b.assign_sub(learning_rate * dloss_db)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzLreVuzMRN6"
      },
      "outputs": [],
      "source": [
        "w.assign([[10.0]])\n",
        "b.assign([0.0])\n",
        "\n",
        "# Create a tf.data.Dataset object for easy batched iteration\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_x.astype(np.float32), train_labels.astype(np.float32)))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(256)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = train_on_batch(tf.reshape(x,(-1,1)), tf.reshape(y,(-1,1)))\n",
        "  print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "13XEEc3FUC_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifcq5EfLMUR4"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0) # pick the seed for reproducibility - change it to explore the effects of random variations\n",
        "\n",
        "n = 100\n",
        "X, Y = make_classification(n_samples = n, n_features=2,\n",
        "                           n_redundant=0, n_informative=2, flip_y=0.05,class_sep=1.5)\n",
        "X = X.astype(np.float32)\n",
        "Y = Y.astype(np.int32)\n",
        "\n",
        "split = [ 70*n//100, (15+70)*n//100 ]\n",
        "train_x, valid_x, test_x = np.split(X, split)\n",
        "train_labels, valid_labels, test_labels = np.split(Y, split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vgOwPPbMjV0"
      },
      "outputs": [],
      "source": [
        "def plot_dataset(features, labels, W=None, b=None):\n",
        "    # prepare the plot\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    ax.set_xlabel('$x_i[0]$ -- (feature 1)')\n",
        "    ax.set_ylabel('$x_i[1]$ -- (feature 2)')\n",
        "    colors = ['r' if l else 'b' for l in labels]\n",
        "    ax.scatter(features[:, 0], features[:, 1], marker='o', c=colors, s=100, alpha = 0.5)\n",
        "    if W is not None:\n",
        "        min_x = min(features[:,0])\n",
        "        max_x = max(features[:,1])\n",
        "        min_y = min(features[:,1])*(1-.1)\n",
        "        max_y = max(features[:,1])*(1+.1)\n",
        "        cx = np.array([min_x,max_x],dtype=np.float32)\n",
        "        cy = (0.5-W[0]*cx-b)/W[1]\n",
        "        ax.plot(cx,cy,'g')\n",
        "        ax.set_ylim(min_y,max_y)\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4L-ZQPIMk7S"
      },
      "outputs": [],
      "source": [
        "plot_dataset(train_x, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gvz8f-RMnKb"
      },
      "outputs": [],
      "source": [
        "train_x_norm = (train_x-np.min(train_x)) / (np.max(train_x)-np.min(train_x))\n",
        "valid_x_norm = (valid_x-np.min(train_x)) / (np.max(train_x)-np.min(train_x))\n",
        "test_x_norm = (test_x-np.min(train_x)) / (np.max(train_x)-np.min(train_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpt5ywenMpmt"
      },
      "outputs": [],
      "source": [
        "W = tf.Variable(tf.random.normal(shape=(2,1)),dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros(shape=(1,),dtype=tf.float32))\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "@tf.function\n",
        "def train_on_batch(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    z = tf.matmul(x, W) + b\n",
        "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=z))\n",
        "  dloss_dw, dloss_db = tape.gradient(loss, [W, b])\n",
        "  W.assign_sub(learning_rate * dloss_dw)\n",
        "  b.assign_sub(learning_rate * dloss_db)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZNnsbqwMtpw"
      },
      "outputs": [],
      "source": [
        "# Create a tf.data.Dataset object for easy batched iteration\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_x_norm.astype(np.float32), train_labels.astype(np.float32)))\n",
        "dataset = dataset.shuffle(128).batch(2)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = train_on_batch(x, tf.expand_dims(y,1))\n",
        "  print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk4u0y-FMzXB"
      },
      "outputs": [],
      "source": [
        "plot_dataset(train_x,train_labels,W.numpy(),b.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiZttnyaM6vv"
      },
      "outputs": [],
      "source": [
        "pred = tf.matmul(test_x,W)+b\n",
        "fig,ax = plt.subplots(1,2)\n",
        "ax[0].scatter(test_x[:,0],test_x[:,1],c=pred[:,0]>0.5)\n",
        "ax[1].scatter(test_x[:,0],test_x[:,1],c=valid_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRM02WJeM-EJ"
      },
      "outputs": [],
      "source": [
        "tf.reduce_mean(tf.cast(((pred[0]>0.5)==test_labels),tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PygxcLDpNFts"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "\n",
        "W = tf.Variable(tf.random.normal(shape=(2,1)))\n",
        "b = tf.Variable(tf.zeros(shape=(1,),dtype=tf.float32))\n",
        "\n",
        "@tf.function\n",
        "def train_on_batch(x, y):\n",
        "  vars = [W, b]\n",
        "  with tf.GradientTape() as tape:\n",
        "    z = tf.sigmoid(tf.matmul(x, W) + b)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(z,y))\n",
        "    correct_prediction = tf.equal(tf.round(y), tf.round(z))\n",
        "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    grads = tape.gradient(loss, vars)\n",
        "    optimizer.apply_gradients(zip(grads,vars))\n",
        "  return loss,acc\n",
        "\n",
        "for epoch in range(20):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss,acc = train_on_batch(tf.reshape(x,(-1,2)), tf.reshape(y,(-1,1)))\n",
        "  print('Epoch %d: last batch loss = %.4f, acc = %.4f' % (epoch, float(loss),acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6imUItgNJpV"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(2,))\n",
        "z = tf.keras.layers.Dense(1,kernel_initializer='glorot_uniform',activation='sigmoid')(inputs)\n",
        "model = tf.keras.models.Model(inputs,z)\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(0.1),'binary_crossentropy',['accuracy'])\n",
        "model.summary()\n",
        "h = model.fit(train_x_norm,train_labels,batch_size=8,epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVChJCXXNPGh"
      },
      "outputs": [],
      "source": [
        "plt.plot(h.history['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsvDbKAENSWx"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(5,activation='sigmoid',input_shape=(2,)))\n",
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(0.1),'binary_crossentropy',['accuracy'])\n",
        "model.summary()\n",
        "model.fit(train_x_norm,train_labels,validation_data=(test_x_norm,test_labels),batch_size=8,epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseNN(tf.Module):\n",
        "  def __init__(self, outputs):\n",
        "    super().__init__()\n",
        "    self.outputs = outputs\n",
        "    self.fl_init = False\n",
        "\n",
        "  def __call__(self, x):\n",
        "    if not self.fl_init:\n",
        "      self.w = tf.random.truncated_normal((x.shape[-1], self.outputs), stddev=0.1, name=\"W\")\n",
        "      self.b = tf.zeros([self.outputs], dtype=tf.float32, name=\"b\")\n",
        "\n",
        "      self.w = tf.Variable(self.w)\n",
        "      self.b = tf.Variable(self.b)\n",
        "\n",
        "      self.fl_init = True\n",
        "    y = x @ self.w + self.b\n",
        "    return y"
      ],
      "metadata": {
        "id": "Tq9EiNgUUj_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DenseNN(1)\n",
        "x_train = tf.random.uniform(minval=0, maxval=10, shape=(100, 2))\n",
        "y_train = [a + b for a, b in x_train]\n",
        "loss = lambda x, y: tf.reduce_mean(tf.square(x - y))\n",
        "\n",
        "opt = tf.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "\n",
        "EPOCHS = 50\n",
        "for n in range(EPOCHS):\n",
        "  for x, y in zip(x_train, y_train):\n",
        "    x = tf.expand_dims(x, axis=0)\n",
        "    y = tf.constant(y, shape=(1, 1))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      f_loss = loss(y, model(x))\n",
        "\n",
        "    grads = tape.gradient(f_loss, model.trainable_variables)\n",
        "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  print(f_loss.numpy())"
      ],
      "metadata": {
        "id": "sgwnKgT6Vey8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model(tf.constant([[1.0, 2.0]])))\n",
        "print(model(tf.constant([[5.0, 2.0]])))"
      ],
      "metadata": {
        "id": "XMrrH64tXIx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "T-k2WgxgXps5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "x_train = tf.reshape(tf.cast(x_train, tf.float32), [-1, 28*28])\n",
        "x_test = tf.reshape(tf.cast(x_test, tf.float32), [-1, 28*28])\n",
        "\n",
        "y_train = to_categorical(y_train, 10)"
      ],
      "metadata": {
        "id": "TgJcrNB7X0ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseNN(tf.Module):\n",
        "  def __init__(self, outputs, activate=\"relu\"):\n",
        "    super().__init__()\n",
        "    self.outputs = outputs\n",
        "    self.activate = activate\n",
        "    self.fl_init = False\n",
        "\n",
        "  def __call__(self, x):\n",
        "    if not self.fl_init:\n",
        "      self.w = tf.random.truncated_normal((x.shape[-1], self.outputs), stddev=0.1, name=\"W\")\n",
        "      self.b = tf.zeros([self.outputs], dtype=tf.float32, name=\"b\")\n",
        "\n",
        "      self.w = tf.Variable(self.w)\n",
        "      self.b = tf.Variable(self.b)\n",
        "\n",
        "      self.fl_init = True\n",
        "    y = x @ self.w + self.b\n",
        "\n",
        "    if self.activate == \"relu\":\n",
        "      return tf.nn.relu(y)\n",
        "    elif self.activate == \"softmax\":\n",
        "      return tf.nn.softmax(y)"
      ],
      "metadata": {
        "id": "xQruXfRtYHKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer = DenseNN(128)\n",
        "output_layer = DenseNN(10, activate=\"softmax\")\n",
        "\n",
        "def model_predict(x):\n",
        "  return output_layer(hidden_layer(x))\n",
        "\n",
        "cross_entropy = lambda y_true, y_pred: tf.reduce_mean(tf.losses.categorical_crossentropy(y_true, y_pred))\n",
        "\n",
        "opt = tf.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "TOTAL = x_train.shape[0]\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "CeZfKW6gYpK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(EPOCHS):\n",
        "  loss = 0\n",
        "  for x_batch, y_batch in train_dataset:\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      f_loss = cross_entropy(y_batch, model_predict(x_batch))\n",
        "    loss += f_loss\n",
        "    grads = tape.gradient(f_loss, [hidden_layer.trainable_variables, output_layer.trainable_variables])\n",
        "    opt.apply_gradients(zip(grads[1], output_layer.trainable_variables))\n",
        "    opt.apply_gradients(zip(grads[0], hidden_layer.trainable_variables))\n",
        "\n",
        "  print(loss.numpy())"
      ],
      "metadata": {
        "id": "rgDw7GhJZlJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = model_predict(x_test)\n",
        "\n",
        "y2 = tf.argmax(y , axis=1).numpy()\n",
        "acc = len(y_test[y_test == y2])/ y_test.shape[0] * 100\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "HDSfj3-gadqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = tf.metrics.Accuracy()\n",
        "acc.update_state(y_test, y2)\n",
        "print(acc.result().numpy() * 100)"
      ],
      "metadata": {
        "id": "NSePlahvawSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_cat = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "25d5vF-McJvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = tf.metrics.Recall()\n",
        "acc.update_state(y_test_cat, y)\n",
        "print(acc.result().numpy() * 100)"
      ],
      "metadata": {
        "id": "1pTKdCACbDoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = tf.metrics.Precision()\n",
        "acc.update_state(y_test_cat, y)\n",
        "print(acc.result().numpy() * 100)"
      ],
      "metadata": {
        "id": "06JSYChvbELw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequentialModule(tf.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_1 = DenseNN(128)\n",
        "    self.layer_2 = DenseNN(10, activate=\"softmax\")\n",
        "\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.layer_2(self.layer_1(x))"
      ],
      "metadata": {
        "id": "WlQqI07FcjBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SequentialModule()\n",
        "print(model.submodules)"
      ],
      "metadata": {
        "id": "6ewP50NtcxOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_batch(x_batch, y_batch):\n",
        "   with tf.GradientTape() as tape:\n",
        "      f_loss = cross_entropy(y_batch, model(x_batch))\n",
        "   grads = tape.gradient(f_loss, model.trainable_variables)\n",
        "   opt.apply_gradients(zip(grads, model.trainable_variables))\n",
        "   return f_loss"
      ],
      "metadata": {
        "id": "OQU4-HPudTWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(EPOCHS):\n",
        "  loss = 0\n",
        "  for x_batch, y_batch in train_dataset:\n",
        "    loss += train_batch(x_batch, y_batch)\n",
        "  print(loss.numpy())"
      ],
      "metadata": {
        "id": "BF2pjpvQc6eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = model(x_test)\n",
        "\n",
        "y2 = tf.argmax(y , axis=1).numpy()\n",
        "acc = len(y_test[y_test == y2])/ y_test.shape[0] * 100\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "AQ__SPQyfqSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D5IMCfPOQzd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpMefX8oQnlT"
      },
      "outputs": [],
      "source": [
        "def check_image_dir(path):\n",
        "    for fn in glob.glob(path):\n",
        "        if not check_image(fn):\n",
        "            print(\"Corrupt image or wrong format: {}\".format(fn))\n",
        "            os.remove(fn)\n",
        "\n",
        "\n",
        "def check_image(fn):\n",
        "    try:\n",
        "        im = Image.open(fn)\n",
        "        im.verify()\n",
        "        return im.format=='JPEG'\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "\n",
        "def display_dataset(dataset, labels=None, n=10, classes=None):\n",
        "    fig,ax = plt.subplots(1,n,figsize=(15,3))\n",
        "    for i in range(n):\n",
        "        ax[i].imshow(dataset[i])\n",
        "        ax[i].axis('off')\n",
        "        if classes is not None and labels is not None:\n",
        "            ax[i].set_title(classes[labels[i][0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWV2JhLYP2oX"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('data/kagglecatsanddogs_5340.zip'):\n",
        "    !wget -P data https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBcxJNzNP8V3"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "if not os.path.exists('data/PetImages'):\n",
        "    with zipfile.ZipFile('data/kagglecatsanddogs_5340.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsKN3zv1QuQ9"
      },
      "outputs": [],
      "source": [
        "check_image_dir('data/PetImages/Cat/*.jpg')\n",
        "check_image_dir('data/PetImages/Dog/*.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZEORo-dQElx"
      },
      "outputs": [],
      "source": [
        "data_dir = 'data/PetImages'\n",
        "batch_size = 64\n",
        "ds_train = keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'training',\n",
        "    seed = 13,\n",
        "    image_size = (224,224),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "ds_test = keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'validation',\n",
        "    seed = 13,\n",
        "    image_size = (224,224),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qqht0eTHQPBX"
      },
      "outputs": [],
      "source": [
        "for x,y in ds_train:\n",
        "    print(f\"Training batch shape: features={x.shape}, labels={y.shape}\")\n",
        "    x_sample, y_sample = x,y\n",
        "    break\n",
        "    \n",
        "display_dataset(x_sample.numpy().astype(np.int),np.expand_dims(y_sample,1),classes=ds_train.class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbUhrtvBQRo1"
      },
      "outputs": [],
      "source": [
        "vgg = keras.applications.VGG16()\n",
        "inp = keras.applications.vgg16.preprocess_input(x_sample[:1])\n",
        "\n",
        "res = vgg(inp)\n",
        "print(f\"Most probable class = {tf.argmax(res,1)}\")\n",
        "\n",
        "keras.applications.vgg16.decode_predictions(res.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E71T0BEsSXaN"
      },
      "outputs": [],
      "source": [
        "vgg.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s41wZ4phScHj"
      },
      "outputs": [],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5i_SZKvSerL"
      },
      "outputs": [],
      "source": [
        "vgg = keras.applications.VGG16(include_top=False)\n",
        "\n",
        "inp = keras.applications.vgg16.preprocess_input(x_sample[:1])\n",
        "res = vgg(inp)\n",
        "print(f\"Shape after applying VGG-16: {res[0].shape}\")\n",
        "plt.figure(figsize=(15,3))\n",
        "plt.imshow(res[0].numpy().reshape(-1,512))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX5skfwGSg0t"
      },
      "outputs": [],
      "source": [
        "num = batch_size*50\n",
        "ds_features_train = ds_train.take(50).map(lambda x,y : (vgg(x),y))\n",
        "ds_features_test = ds_test.take(10).map(lambda x,y : (vgg(x),y))\n",
        "\n",
        "for x,y in ds_features_train:\n",
        "    print(x.shape,y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pd4TcLQRSkwP"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(7,7,512)),\n",
        "    keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "hist = model.fit(ds_features_train, validation_data=ds_features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozLbxYbCS_9X"
      },
      "outputs": [],
      "source": [
        "# Encoder - Decoder"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}